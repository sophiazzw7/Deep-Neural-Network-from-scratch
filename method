OGM finding list:


Here's a revised and consolidated list of OGM findings that maintains the necessary information while keeping it concise:



### **OGM Finding List:**

1. **F_001:** Please provide a comprehensive list of model stakeholders and their specific responsibilities related to the OGM process.

2.  Please expand the definition and support for the thresholds used in the OGM plan (e.g., <5% error for tellers and <20% error for platform), including a detailed justification based on model-specific characteristics and/or quantitative analysis.

3. Please provide metrics for assessing model robustness/stability and sensitivity analysis. Detailed justification should be provided if these metrics are not applicable.
4. **F_004:** Please provide an early warning metric in the OGM plan to preemptively alert the team before significant deviations or threshold breaches occur.

5. **F_005:** Please review and specify the frequency of evaluation of model assumption & limitations, including any compensating measures applied.

6. **F_006:** Please provide documentation on data controls, including data validation, data lineage, and controls ensuring data consistency and completeness.

7. **F_007:** The OGM plan does not include benchmarking of the model against industry standards or external benchmarks.

8. **F_008:** Please provide justification for the allowable range of overrides (0.01 to 13 times), and ensure controls are in place to monitor and assess their long-term impact on model performance, including the magnitude, trend, and relevancy of overrides.


9.  Model inputs are not monitored through the OGM process to ensure the quality, reliability, and consistency of the input data used to generate the model's predictions. 

11. **F_011:** Detailed OGM reports and override tracking reports for 2022 and 2023 were not found in MIMS. Please ensure these reports are documented and available for review.









Please provide the following documentation regarding model development data:

Provide a detailed data dictionary with variable creation rules, units, decoding rules, and descriptive statistics (mean, median, standard deviation, and frequency distribution).
Document the full data cleaning process, including smoothing, transformations (e.g., normalization, clustering), and justification for backfilling or corrections.
Provide a comprehensive assessment of data quality, addressing outliers, missing, corrupted, incomplete, and duplicated data, along with consistency checks and proper treatment methodologies.
Provide an evaluation of data sources' reliability, representativeness, and statistical validation of assumptions, particularly for historical data suitability in forecasting.
Document sampling, re-sampling, and partitioning methodologies.
Provide code documentation for processing source data into intermediate and final model datasets.


from Model Documentation Review):

1. Model risk tier support table should be updated.
2. MDD should confirm to the new MDD template.

Model controls findings: 
Finding 1: Lack of Justification for Override Range The wide allowable override range (0.01 to 13 times the output) lacks documented rationale. 
Finding 2: Insufficient Override Monitoring Controls Controls to ensure overrides stay within the allowed range are not well-established. 
3. Model version update not reflected in MDD. Vendor name should be consistent in MDD
