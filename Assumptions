Below is a concise summary of the **key assumptions** and **key limitations** for the **four quantitative segments**—Internal Fraud (IF), Damage to Physical Assets (DPA), Employment Practices and Workplace Safety (EPWS), and Execution, Delivery, and Process Management (EDPM)—based on the provided material.

---

## 1. **Key Assumptions**

1. **Loss Distribution & Non-Regression Multiplier**  
   - The model uses a Loss Distribution Approach (LDA) combined with a “non-regression multiplier” for severity.  
   - It assumes that operational loss frequency and average severity can be treated separately, with minimal correlation between the two.

2. **Severity Calculation**  
   - Severity is determined by comparing a non-stress average vs. a stress average over a 9-quarter window.  
   - Each event type has **one** stress average, applied uniformly across all stress scenarios.  
   - The severity does **not** directly rely on macroeconomic variables; rather, it hinges on whether a scenario is “baseline” or “stress.”

3. **Archer Data Source**  
   - **All event data** at or above \$10K net loss is pulled from Archer, capturing the most material operational losses.  
   - The data set spans **2005.Q1–2021.Q4**, assumed to be representative of both normal and stressed economic conditions (including the Great Financial Crisis).

4. **Historical Representativeness**  
   - The historical loss frequency and severity from Archer are presumed sufficient for projecting future losses via the multiplier method.  
   - Data cleansing and manual exclusions are done carefully, and the team relies on these processes to ensure data accuracy.

5. **Model Execution Assumptions**  
   - The approach follows standard count-data assumptions for frequency (though the actual method here is a multiplier rather than regression).  
   - Model execution relies on timely and accurate data availability; no ad-hoc process deviations are planned once the approach is approved.

---

## 2. **Key Limitations**

1. **Single Stress Average Severity**  
   - Using **one** stress average multiplier for each event type reduces scenario specificity (e.g., no differentiation among mild, moderate, or severe economic downturns).

2. **Data Sparsity & Variability**  
   - Some event types have **limited historical observations**, complicating frequency or severity estimates.  
   - Operational losses tend to be random and can be **heavy-tailed**, introducing volatility in model predictions.

3. **Historical Bias**  
   - Reliance on past data (2005 onward) may not capture future structural changes or emerging risks.  
   - If new loss behaviors deviate significantly from historical patterns, the multiplier approach may be less reliable.

4. **Manual Data Processes**  
   - Potential inconsistencies exist in data entry and recovery restatement, requiring subject-matter expert review.  
   - Capping, exclusions, or reversals could alter the data set, and the model depends on how accurately these adjustments are documented.

5. **Model Stability**  
   - Past stress-testing cycles revealed that purely quantitative methods faced stability issues (one factor prompting a qualitative approach for certain segments).  
   - Heavy reliance on historical severity distributions means the model may require overlays to generate reasonable outputs under drastically changing conditions.

---

## 3. **Additional Context: Qualitative vs. Quantitative Segments**

- **EF (External Fraud)** and **CPBP (Clients, Products, and Business Practices)** transitioned to a **qualitative** approach due to the model’s inability to capture those segments effectively with purely quantitative methods.  
- The assumptions and limitations summarized here apply to the **four quantitative segments**—IF, DPA, EPWS, and EDPM.

---

### **In Summary**

- **Four Segments (IF, DPA, EPWS, EDPM)** rely on a non-regression multiplier approach for severity, supported by Archer data (≥\$10K) from 2005 to 2021.  
- Key **assumptions** center on the sufficiency and representativeness of historical loss data, an independently modeled frequency and severity framework, and stable data processes.  
- Key **limitations** include a single stress multiplier for severity, potential data sparsity in some event types, the inherently random nature of operational losses, and reliance on manual data entry and adjustments.
